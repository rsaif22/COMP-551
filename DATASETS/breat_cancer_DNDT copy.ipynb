{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 2) 2 (569, 31)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define a simple label encoder function\n",
    "def encode_column(column):\n",
    "    if column.dtype == object:\n",
    "        column = column.astype('category').cat.codes\n",
    "    return column\n",
    "\n",
    "# Apply the encoder to each column\n",
    "\n",
    "# Assuming 'data.csv' is your CSV file\n",
    "df = pd.read_csv('breast-cancer-wisconsin-data.csv')\n",
    "df = df.apply(encode_column)\n",
    "#print(df.head())\n",
    "# Separate the features and the target variable\n",
    "#buying,maint,doors,persons,lug_boot,safety low,eval\n",
    "#\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\",\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df[[\"id\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"]].to_numpy()\n",
    "#X = df[['buying','maint','doors','persons','lug_boot','safety']].to_numpy()\n",
    "y = df['diagnosis'].to_numpy()\n",
    "#print(y)\n",
    "#print(X)\n",
    " #TODO: ommit patient id\n",
    "# Remove patient id\n",
    "# Convert the species labels to integers\n",
    "species_to_int = {species: idx for idx, species in enumerate(np.unique(y))}\n",
    "y_int = np.array([species_to_int[eval] for eval in y])\n",
    "\n",
    "# Optionally, convert the integer labels to one-hot encoding\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "num_classes = len(species_to_int)\n",
    "y_one_hot = one_hot_encode(y_int, num_classes)\n",
    "print(y_one_hot.shape, num_classes, X.shape)\n",
    "#print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[:,1:]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Convert to PyTorch tensors\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y_int, dtype=torch.int64).to(device)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tensor, y_tensor, test_size=0.2, random_state=1973)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tensor -= x_tensor.mean(dim=0)\n",
    "# x_tensor /= x_tensor.std(dim=0)\n",
    "mean = x_train.mean(dim=0)\n",
    "std = x_train.std(dim=0)\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_tensor, y_tensor, test_size=0.2, random_state=1973)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6657, Accuracy: 0.8509\n",
      "Epoch [2/10], Loss: 0.5916, Accuracy: 0.8772\n",
      "Epoch [3/10], Loss: 0.5075, Accuracy: 0.9123\n",
      "Epoch [4/10], Loss: 0.4389, Accuracy: 0.9298\n",
      "Epoch [5/10], Loss: 0.4011, Accuracy: 0.9474\n",
      "Epoch [6/10], Loss: 0.3816, Accuracy: 0.9474\n",
      "Epoch [7/10], Loss: 0.3690, Accuracy: 0.9649\n",
      "Epoch [8/10], Loss: 0.3604, Accuracy: 0.9737\n",
      "Epoch [9/10], Loss: 0.3531, Accuracy: 0.9912\n",
      "Epoch [10/10], Loss: 0.3488, Accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=30, out_features=50, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_class = 2\n",
    "d = X.shape[1]\n",
    "from nn_model import NeuralNetwork\n",
    "model = NeuralNetwork(d, 50, num_class).to(device)\n",
    "\n",
    "model.fit(x_train, y_train, x_test, y_test, epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "True\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "print(model.predict(x_test))\n",
    "print(\"True\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(x_test)\n",
    "acc = (y_pred == y_test).float().mean()\n",
    "print('Accuracy: {:.2f}%'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "cut_points_list = [torch.nn.Parameter(torch.rand(i)) for i in num_cut]\n",
    "leaf_score = torch.nn.Parameter(torch.rand(num_leaf, num_class))\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = torch.optim.Adam([*cut_points_list, leaf_score], lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684697687625885\n",
      "0.2382846623659134\n",
      "0.22305907309055328\n",
      "0.22055937349796295\n",
      "0.22198253870010376\n"
     ]
    }
   ],
   "source": [
    "from pytorch_neural import nn_decision_tree\n",
    "# Training loop\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = nn_decision_tree(x_tensor, cut_points_list, leaf_score, temperature=0.1)\n",
    "    loss = loss_fn(y_pred, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate 0.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    y_pred_eval = nn_decision_tree(x_tensor, cut_points_list, leaf_score, temperature=0.1)\n",
    "    error_rate = 1 - (y_pred_eval.argmax(1) == y_tensor.argmax(1)).float().mean()\n",
    "    print('error rate %.2f' % error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121265377855887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = nn_decision_tree(x_tensor, cut_points_list, leaf_score, temperature=0.1)\n",
    "accuracy_score(y_tensor.argmax(1), y_pred.argmax(1))\n",
    "print(accuracy_score(y_tensor.argmax(1), y_pred.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x0 = np.repeat(np.linspace(0, np.max(X[:,0]), 100), 100).reshape(-1,1)\n",
    "sample_x1 = np.tile(np.linspace(0, np.max(X[:,1]), 100).reshape(-1,1), [100,1])\n",
    "sample_x = np.hstack([sample_x0, sample_x1])\n",
    "sample_x_tensor = torch.tensor(sample_x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10000x0 and 1x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alexander\\Documents\\GitHub\\COMP-551\\DATASETS\\breat_cancer_DNDT.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alexander/Documents/GitHub/COMP-551/DATASETS/breat_cancer_DNDT.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alexander/Documents/GitHub/COMP-551/DATASETS/breat_cancer_DNDT.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alexander/Documents/GitHub/COMP-551/DATASETS/breat_cancer_DNDT.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     sample_label \u001b[39m=\u001b[39m nn_decision_tree(sample_x_tensor, cut_points_list, leaf_score, temperature\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alexander/Documents/GitHub/COMP-551/DATASETS/breat_cancer_DNDT.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alexander/Documents/GitHub/COMP-551/DATASETS/breat_cancer_DNDT.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(X[:,\u001b[39m0\u001b[39m], X[:,\u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39margmax(y_one_hot, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), marker\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, s\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummer\u001b[39m\u001b[39m'\u001b[39m, edgecolors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alexander\\Documents\\GitHub\\COMP-551\\DATASETS\\pytorch_neural.py:19\u001b[0m, in \u001b[0;36mnn_decision_tree\u001b[1;34m(x, cut_points_list, leaf_score, temperature)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnn_decision_tree\u001b[39m(x, cut_points_list, leaf_score, temperature\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     leaf \u001b[39m=\u001b[39m reduce(torch_kron_prod, \n\u001b[0;32m     20\u001b[0m                   \u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m z: torch_bin(x[:, z[\u001b[39m0\u001b[39;49m]:z[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m], z[\u001b[39m1\u001b[39;49m], temperature), \u001b[39menumerate\u001b[39;49m(cut_points_list)))\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmatmul(leaf, leaf_score)\n",
      "File \u001b[1;32mc:\\Users\\Alexander\\Documents\\GitHub\\COMP-551\\DATASETS\\pytorch_neural.py:20\u001b[0m, in \u001b[0;36mnn_decision_tree.<locals>.<lambda>\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnn_decision_tree\u001b[39m(x, cut_points_list, leaf_score, temperature\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m):\n\u001b[0;32m     19\u001b[0m     leaf \u001b[39m=\u001b[39m reduce(torch_kron_prod, \n\u001b[1;32m---> 20\u001b[0m                   \u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m z: torch_bin(x[:, z[\u001b[39m0\u001b[39;49m]:z[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m], z[\u001b[39m1\u001b[39;49m], temperature), \u001b[39menumerate\u001b[39m(cut_points_list)))\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmatmul(leaf, leaf_score)\n",
      "File \u001b[1;32mc:\\Users\\Alexander\\Documents\\GitHub\\COMP-551\\DATASETS\\pytorch_neural.py:14\u001b[0m, in \u001b[0;36mtorch_bin\u001b[1;34m(x, cut_points, temperature)\u001b[0m\n\u001b[0;32m     12\u001b[0m cut_points \u001b[39m=\u001b[39m cut_points\u001b[39m.\u001b[39msort()[\u001b[39m0\u001b[39m]  \u001b[39m# make sure cut_points is monotonically increasing\u001b[39;00m\n\u001b[0;32m     13\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcumsum(torch\u001b[39m.\u001b[39mcat([torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.0\u001b[39m]), \u001b[39m-\u001b[39mcut_points]), \u001b[39m0\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(x, W) \u001b[39m+\u001b[39m b\n\u001b[0;32m     15\u001b[0m res \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(h \u001b[39m/\u001b[39m temperature, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10000x0 and 1x2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with torch.no_grad():\n",
    "    sample_label = nn_decision_tree(sample_x_tensor, cut_points_list, leaf_score, temperature=0.1).argmax(1)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X[:,0], X[:,1], c=np.argmax(y_one_hot, axis=1), marker='o', s=50, cmap='summer', edgecolors='black')\n",
    "plt.scatter(sample_x0.flatten(), sample_x1.flatten(), c=sample_label.numpy().flatten(), marker='D', s=20, cmap='summer', edgecolors='none', alpha=0.33)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
